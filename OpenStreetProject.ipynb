{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Using OpenStreetMap Data to Explore Providence, RI</center>\n",
    "## <Center>Map Area</Center>\n",
    "\n",
    "<center><img src=\"PVD_map.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/></center>\n",
    "\n",
    "\n",
    "Providence, RI, United States\n",
    "\n",
    "- [https://www.openstreetmap.org/relation/191210](https://www.openstreetmap.org/relation/191210)\n",
    "- [http://overpass-api.de/query_form.html](http://overpass-api.de/query_form.html)\n",
    ">**Overpass API > Query**: (node(41.7416, -71.5461, 41.8926, -71.3006);<;); out meta;  \n",
    "\n",
    "#### Why Providence?\n",
    ">I am currently searching for a new apartment in Providence, and I have questions about the local amenities available in different neighborhoods. In this project, I will use OpenStreetMap data to address some of my questions. For the benefit of future residents, I will also make suggestions to OpenStreetMap.org to ensure a clear and accurate representation of Providence in the database. \n",
    "\n",
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u>Data Audit</u></center>\n",
    "After exporting the OpenStreetMap data using the overpass-api query listed above, I began the process of auditing to identity any problems with the data. \n",
    "\n",
    "### <Center>Problems with State Names</Center>\n",
    "#### List of States:  \n",
    ">RI 557  \n",
    "Massachusetts 1  \n",
    "MA 4  \n",
    "ri 9  \n",
    "Rhode Island 7\n",
    "\n",
    "#### Check for Validity \n",
    ">As seen in the output copied above, three of the listed state names do not conform to the convention used for states in the OpenStreetMap data (i.e., a capitalized two-letter abbreviation). The three names that do not conform to this convention will be modified during the cleaning phase to better align with the naming convention.\n",
    "\n",
    "#### Check for Accuracy\n",
    "> Both Massachusetts and Rhode Island appear in the OSM map of the area surrounding Providence. It therefore makes sense that nodes and ways from both states would appear in the data. No change is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Problems with City Names</center>\n",
    "\n",
    "#### List of Cities:  \n",
    ">Providence 204  \n",
    "Cranston 67  \n",
    "Central Falls 6  \n",
    "East Providence 17  \n",
    "Pawtucket 33  \n",
    "North Providence 20  \n",
    "Johnston 31  \n",
    "Seekonk 9  \n",
    "cranston 1  \n",
    "Barrington 100  \n",
    "Rumford 6  \n",
    "Smithfield 4  \n",
    "providence 4  \n",
    "Warwick 5  \n",
    "Barrington, Rhode Island 2  \n",
    "Lincoln 2  \n",
    "\n",
    "#### Check for Validity\n",
    ">As seen in the output above, two of the city name values are not capitalized and one of the values for city includes both the city and state. In the data cleaning phase, all words that do not start with capital letters will be modified to begin with capital letters. Additionally, for the entry that includes both the city and state, the state will be removed.\n",
    "\n",
    "#### Check for Accuracy\n",
    ">To check for accuracy, I used the code below to ensure that if a city and state were both listed for an entry, the city actually existed within the state (i.e., if the state was Rhode Island, then the city should be a city within Rhode Island). No discrepancies were identified and, thus, no changes were required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python3 Code\n",
    "    def state_check(filename):\n",
    "            osm_file = open(filename, 'r')\n",
    "            mass_cities = ['Seekonk']\n",
    "            ri_cities = ['Providence', 'Cranston', 'Central Falls', 'East Providence', 'Pawtucket', \n",
    "            'North Providence', 'Johnston', 'cranston', 'Barrington', 'Rumford', 'Smithfield', 'providence',\n",
    "            'Warwick', 'Barrington, Rhode Island', 'Lincoln'] \n",
    "            \n",
    "            for event, elem in ET.iterparse(osm_file):\n",
    "                if elem.tag == 'way' or elem.tag == 'node':\n",
    "                    state = find_state(elem)\n",
    "                    city = find_city(elem)\n",
    "                    if city:\n",
    "                        if state:\n",
    "                            if(state == 'MA') and (city not in mass_cities):\n",
    "                                print('Missmatch - The following city is not in Mass: '+city)\n",
    "                                print(elem.attrib['id'])\n",
    "                                print(elem.attrib['lat'],elem.attrib['lon'])\n",
    "                                for tag in elem.iter(\"tag\"):\n",
    "                                    print(tag.attrib['k'],tag.attrib['v'])\n",
    "                                print()\n",
    "                            elif (state == 'RI') and (city not in ri_cities):\n",
    "                                print('Missmatch - The following city is not in RI:' +city)\n",
    "                                print(elem.attrib['id'])\n",
    "                                print(elem.attrib['lat'],elem.attrib['lon'])\n",
    "                                for tag in elem.iter(\"tag\"):\n",
    "                                    print(tag.attrib['k'],tag.attrib['v'])\n",
    "                                print()\n",
    "\n",
    "    state_check('Providence')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Problems with Zipcodes</center>\n",
    "\n",
    "#### List of Zipcodes:  \n",
    ">02903 37  \n",
    "02908 22  \n",
    "02910 48  \n",
    "02863 5  \n",
    "02914 15  \n",
    "02860 23  \n",
    "02906 47  \n",
    "02905 11  \n",
    "02919 31  \n",
    "02920 45  \n",
    "02915 4  \n",
    "02866 1  \n",
    "02911 5  \n",
    "02904 19  \n",
    "02909 9  \n",
    "02806 101  \n",
    "02916 6  \n",
    "02861 8  \n",
    "02917 5  \n",
    "02912 113  \n",
    "02907 45  \n",
    "02901 2  \n",
    "02888 4   \n",
    "02771 8  \n",
    "02921 2  \n",
    "02918 1  \n",
    "02912 Unset 1  \n",
    "02906-1189 1  \n",
    "029212 1  \n",
    "02903-2996 1  \n",
    "02865 2  \n",
    "02906-4800 1  \n",
    "\n",
    "#### Checking for Validity\n",
    ">As seen in the output above, three of the zipcodes include additional four-digit delivery sector codes following the primary five-digit zipcode. To conform to the convention used by OpenStreetMap, the data will be cleaned to remove the delivery sector codes and inlcude only the five-digit zipcode. For the \"Unset\" zipcode, I confirmed its accuracy and will remove the \"unset\" marker in the cleaning process. \n",
    "\n",
    "#### Checking for Accuracy\n",
    ">I used the code below to check each entry to ensure that, if a city and zipcode were both listed in a given entry, the zipcode actually appeared within the city. To check for this, I generated a dictionary of zipcodes for each city based on the database of zipcodes maintained by UnitedStatesZipcodes.org. In addition to the invalidly coded zipcodes identified above, the program identified two entries with zipcodes that did no appear in the listed city. After reviewing other identifying data for the entry (e.g., street address, location name, latitude and longitude), it became clear that the zipcode was inaccurately listed. During the cleaning process, the inaccurate zipcodes will be replaced by the correct zipcodes for those locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python3 Code\n",
    "    def zipcode_check(filename):\n",
    "        zipcode_dict = {\n",
    "            'Seekonk':['02771'],\n",
    "            'Providence':['02909','02908', '02906','02907','02905','02904','02903','02911','02910',\n",
    "            '02860','02919','02920','02912','02902','02918','02901','02940'],\n",
    "            'Cranston':['02920','02910','02921','02905','02831','02907','02909'],\n",
    "            'Central Falls':['02863'],\n",
    "            'East Providence':['02914','02915','02916','02860'],\n",
    "            'Pawtucket':['02860','02861','02863','02862'],\n",
    "            'North Providence':['02911','02904'],\n",
    "            'Johnston':['02919'],\n",
    "            'Barrington':['02806'],\n",
    "            'Rumford':['02916'],\n",
    "            'Smithfield':['02917'],\n",
    "            'Warwick':['02886','02889','02888','02818','02893','02887'],\n",
    "            'Lincoln':['02865']}\n",
    "        osm_file = open(filename, 'r')\n",
    "        n = 1\n",
    "        for event, elem in ET.iterparse(osm_file):\n",
    "            if elem.tag == 'way' or elem.tag == 'node':\n",
    "                zipcode = find_zipcode(elem)\n",
    "                city = find_city(elem)\n",
    "                if zipcode:\n",
    "                    if city:\n",
    "                        if zipcode not in zipcode_dict[city]:\n",
    "                            print(n)\n",
    "                            print('Missmatch: '+ zipcode + \" not in \" + city)\n",
    "                            print(elem.attrib['id'])\n",
    "                            try:\n",
    "                                print(elem.attrib['lat'],elem.attrib['lon'])\n",
    "                            except:\n",
    "                                pass\n",
    "                            for tag in elem.iter(\"tag\"):\n",
    "                                print(tag.attrib['k'],tag.attrib['v'])\n",
    "                            print()\n",
    "                            n+=1\n",
    "\n",
    "    zipcode_check('Providence') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Problems with Street Names</center>\n",
    "\n",
    "#### Dictionary of Unexpected Street Suffixes\n",
    ">'Alley': {'Fones Alley'}  \n",
    " 'Ave': {'Atwood Ave',\n",
    "         'Elmwood Ave',\n",
    "         'Park Ave',\n",
    "         'Reservoir Ave',\n",
    "         'Wayland Ave'}  \n",
    " 'BowenStreet': {'BowenStreet'}  \n",
    " 'Broadway': {'Broadway'}  \n",
    " 'Highway': {'Middle Highway'}  \n",
    " 'Hill': {'Capitol Hill'}  \n",
    " 'Pike': {'Putnam Pike'}  \n",
    " 'Plaza': {'Kennedy Plaza', 'Regency Plaza'}  \n",
    " 'Rd': {'Budlong Rd'}  \n",
    " 'Sq.': {'Cunningham Sq.'}  \n",
    " 'St': {'Cushing St', 'Pitman St', 'Cranston St', 'Briggs St'}  \n",
    " 'Way': {'Recreation Way', 'Iron Horse Way'}  \n",
    " 'Wy': {'Iron Horse Wy'}\n",
    " \n",
    "#### Check for Validity\n",
    ">Code (recreated below) was written to test the last word of any street name against a list of common street suffixes. If the last word of a given street name was not included among the list of suffixes, it was added as a key to a dictionary of uncommon street endings. The entire street name was included within a list of values for that key. As you can see from the output above, some street endings are either valid, but uncommon suffixs (e.g., Hill, Highway, Alley) or reflect one word street names (e.g., Broadway). Although these streets do not appear in the list of common suffixes, they are still valid and do not need to be changed. Other entries reflect abbreviations that do not conform to OpenStreetMap conventions (e.g., Wy, St, Sq.) and will be modified during the data cleaning phase. \n",
    "\n",
    "#### Check for Accuracy\n",
    ">A check for accurcy was not conducted. It is beyond the scope of this current project to determine whether each street name that appears in the data is actually a street name that appears in a given city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python3 Code\n",
    "    street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "    street_types = defaultdict(set)\n",
    "    osm_file = open('Providence', 'r')\n",
    "\n",
    "    expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \n",
    "    \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "    def audit_street_types(street_types, street_name):\n",
    "        m = street_type_re.search(street_name)\n",
    "        if m:\n",
    "            street_type = m.group()\n",
    "            if street_type not in expected:\n",
    "                street_types[street_type].add(street_name)\n",
    "\n",
    "    def is_street_name(elem):\n",
    "        return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "    def audit(filename):\n",
    "        for event, elem in ET.iterparse(filename, events=(\"start\",)):\n",
    "            if elem.tag == \"way\":\n",
    "                for tag in elem.iter(\"tag\"):\n",
    "                    if is_street_name(tag):\n",
    "                        audit_street_types(street_types, tag.attrib['v'])\n",
    "        pprint.pprint(dict(street_types))\n",
    "\n",
    "    audit(osm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center><u>Data Cleaning</u></Center>\n",
    "\n",
    "Following the audit, code (available in \"OSM_Cleaning\" file) was used to modify the OpenStreetMap data based on the corrections idenfied during the audit phase and then save the cleaned data in a new OSM file called (\"Providence_Clean\"). \n",
    "\n",
    "## <Center><u>Data Transformation</u></Center>\n",
    "\n",
    "Additional code (available in \"OSM_Creating_CSV\" file) was used to transform the XML data contained within the cleaned Providence OSM file into .csv files that could be easily imported as tables in SQL. The new files are structured to match the scemas that will be used in the SQL tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u>Creating the SQL Tables</u></center>\n",
    "\n",
    "The following code was used to create SQL tables. \n",
    "\n",
    "    create table pvd_nodes(ID integer [PRIMARY KEY], Lat numeric, Lon numeric, \n",
    "    User text, UserID integer, Version integer, ChangeSet integer, Timestamp timestamp) ;\n",
    "    .mode csv \n",
    "    .import PVD_nodes.csv pvd_nodes \n",
    "\n",
    "    create table pvd_nodes_tags(ID integer [PRIMARY KEY], Key text, Value text, Type text) ;\n",
    "    .mode csv \n",
    "    .import PVD_nodes_tags.csv pvd_nodes_tags \n",
    "\n",
    "    create table pvd_ways(ID integer [PRIMARY KEY], User text, UserID integer, \n",
    "    Version integer, ChangeSet integer, Timestamp timestamp) ;\n",
    "    .mode csv \n",
    "    .import PVD_ways.csv pvd_ways \n",
    "\n",
    "    create table pvd_ways_nodes(ID integer [PRIMARY KEY], Node_ID integer, Position integer) ;\n",
    "    .mode csv \n",
    "    .import PVD_ways_nodes.csv pvd_ways_nodes \n",
    "\n",
    "    create table pvd_ways_tags(ID integer [PRIMARY KEY], Key text, Value text, Type text) ;\n",
    "    .mode csv \n",
    "    .import PVD_ways_tags.csv pvd_ways_tags \n",
    "    ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u>About the Data</u></center>\n",
    "\n",
    "### File Sizes\n",
    ">Providence_Clean.osm .......71.8 MB  \n",
    "pvd.db..................................38.5 MB  \n",
    "PVD_nodes.csv....................25.7 MB  \n",
    "PVD_nodes_tags.csv.............1.4 MB  \n",
    "PVD_ways.csv........................2.7 MB  \n",
    "PVD_ways_nodes.csv............8.7 MB  \n",
    "PVD_ways_tags.csv...............4.7 MB\n",
    "\n",
    "#### Python3 Code\n",
    "    def convert_bytes(num):\n",
    "        for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "            if num < 1024.0:\n",
    "                return \"%3.1f %s\" % (num, x)\n",
    "            num /= 1024.0\n",
    "\n",
    "    def file_size(file_path):\n",
    "        if os.path.isfile(file_path):\n",
    "            file_info = os.stat(file_path)\n",
    "            return convert_bytes(file_info.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes\n",
    "313,591\n",
    "\n",
    "    sqlite3> SELECT COUNT(*) FROM pvd_nodes;\n",
    "\n",
    "### Number of Ways\n",
    "46,648\n",
    "\n",
    "    sqlite3> SELECT COUNT(*) FROM pvd_ways;\n",
    "\n",
    "### Number of Unique Contributers\n",
    "450\n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT COUNT(DISTINCT(all_users.UserID))          \n",
    "    FROM (SELECT UserID FROM pvd_nodes UNION ALL SELECT UserID FROM pvd_ways)  as all_users;\n",
    "\n",
    "    \n",
    "### Top Contributers\n",
    "\n",
    "greggerm|108876  \n",
    "woodpeck_fixbot|63399  \n",
    "jremillard-massgis|57303  \n",
    "Zirnch|29503  \n",
    "John Wrenn|9266\n",
    "Alex KG Ellis|7749  \n",
    "jerryam|7352  \n",
    "MassGIS Import|6313  \n",
    "bot-mode|6306  \n",
    "EmilyPPP|4685\n",
    "\n",
    "    sqlite3 > \n",
    "    SELECT all_users.User, COUNT(*) as num\n",
    "    FROM (SELECT User FROM pvd_nodes UNION ALL SELECT User FROM pvd_ways) as all_users\n",
    "    GROUP BY all_users.user\n",
    "    ORDER BY num DESC\n",
    "    LIMIT 10;\n",
    "    \n",
    "\n",
    "\n",
    "### Number of Contributions by Year\n",
    "\n",
    "2007|6,320  \n",
    "2008|447  \n",
    "2009|69,339  \n",
    "2010|801  \n",
    "2011|44,458  \n",
    "2012|47,189  \n",
    "2013|86,395  \n",
    "2014|16,925  \n",
    "2015|20,414  \n",
    "2016|31,554  \n",
    "2017|36,397  \n",
    "\n",
    "    sqlite3 >  \n",
    "    SELECT strftime('%Y', all_entries.timestamp) as year, COUNT(*)\n",
    "    FROM (SELECT ID, Timestamp FROM pvd_nodes UNION ALL SELECT ID, Timestamp FROM pvd_ways) as all_entries\n",
    "    GROUP BY year;\n",
    "\n",
    "### Recommendations for Improving the Data\n",
    "\n",
    "Given the fluctuations in contributions over the 11-year period in which users made changes to the OpenStreetMap data for Providence RI, it would be interesting to identify any events that may have prompted increases or decreases in the number of contributions for a given year. Specifically, given the strikingly low number of contributions made in 2008 an 2010, I am curious if anything happened during those years that discouraged or prevented changes to the data. Similarly, I want to know what may have led to higher numbers of contributions in 2009 and 2013. Having an understanding of contextual and historical factors that correspond to fluctuations in contributor activity can provide insight into what might be done to promote future contributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <Center><u>Exploratory Analyses</u></Center>\n",
    "\n",
    "My exploratory analyses are guided by a desire to decide between two areas to which I am searching for apartments. I would like to compare the different amentities available in each neighborhood. \n",
    "\n",
    "### Neighborhood Comparisons\n",
    "\n",
    "The two neighborhoods to which I am considering moving are College Hill/East Side of Providence and Federal Hill/Downtown Providence. To facilitate my exploration of these neighborhoods, I first had to identify their boundaries. I superimposed a neighborhood map over the map used by OpenStreetMap, and marked rectangles over the neighboorhoods of interest. I used rectangles because this allowed me to specifcy latitude and longitude ranges 33containing each area (which could be used in SQL queries).  \n",
    "\n",
    "<img src=\"PVD_Neighborhood_Map_v2.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "<Center><b>Map of Providence Neighborhood</b></Center>  \n",
    "<Center>Boxes 1 and 2 cover College Hill/East Side and Box 3 covers Federal Hill/Downtown Providence</Center>\n",
    "\n",
    "\n",
    "\n",
    "#### Top Five Amenities in Each Neighborhood\n",
    "Hoping to get a sense of the flavor of both neighborhoods, I initially decided to search to see what the top five amenities were in each.\n",
    "\n",
    ">College Hill/East Providence\n",
    ">>place_of_worship,28  \n",
    "school,25  \n",
    "bench,23  \n",
    "restaurant,20  \n",
    "cafe,18  \n",
    "\n",
    ">Federal Hill/Downtown Providence\n",
    ">>bench,34  \n",
    "waste_basket,16  \n",
    "cafe,11  \n",
    "social_facility,10  \n",
    "place_of_worship,8  \n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Key = \"amenity\") and \n",
    "    (((pvd_nodes.Lon >= -71.41) and (pvd_nodes.Lon <= -71.38) and \n",
    "    (pvd_nodes.Lat >= 41.825) and (pvd_nodes.Lat <= 41.857)) or \n",
    "    ((pvd_nodes.Lon >= -71.407) and (pvd_nodes.Lon <= -71.385) and \n",
    "    (pvd_nodes.Lat >= 41.818) and (pvd_nodes.Lat <= 41.825)))\n",
    "    group by pvd_nodes_tags.value\n",
    "    order by num desc \n",
    "    limit 5;\n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Key = \"amenity\") and \n",
    "    (pvd_nodes.Lon <= -71.36) and \n",
    "    (pvd_nodes.Lon >= -71.407) and \n",
    "    (pvd_nodes.Lat >= 41.813) and \n",
    "    (pvd_nodes.Lat <= 41.825)\n",
    "    group by pvd_nodes_tags.value\n",
    "    order by num desc \n",
    "    limit 5;\n",
    "    \n",
    "#### Number of Dry Cleaners in Each Neighborhood\n",
    "In the past, I have made the mistake of not looking to see if there are local dry cleaners within walking distance of prospective apartments. For the current search, I want to determine the availability of dry cleaners within each neighborhood. \n",
    "\n",
    ">College Hill/East Providence\n",
    ">> 0\n",
    "\n",
    ">Federal Hill/Downtown Providence\n",
    ">> 0\n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Value = \"dry_cleaning\") and \n",
    "    (((pvd_nodes.Lon >= -71.41) and (pvd_nodes.Lon <= -71.38) and \n",
    "    (pvd_nodes.Lat >= 41.825) and (pvd_nodes.Lat <= 41.857)) or \n",
    "    ((pvd_nodes.Lon >= -71.407) and (pvd_nodes.Lon <= -71.385) and \n",
    "    (pvd_nodes.Lat >= 41.818) and (pvd_nodes.Lat <= 41.825)));\n",
    "    \n",
    "    sqlite3 > \n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Value = \"dry_cleaning\") and \n",
    "    (pvd_nodes.Lon <= -71.36) and \n",
    "    (pvd_nodes.Lon >= -71.407) and \n",
    "    (pvd_nodes.Lat >= 41.813) and \n",
    "    (pvd_nodes.Lat <= 41.825);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Libraries\n",
    "As I spend a lot of time completing projects independenlty outside of an office, I wanted to determine if there quite spaces where I might be able to work rather than in my apartment.\n",
    "\n",
    ">College Hill/East Providence\n",
    ">> 8 \n",
    "\n",
    ">Federal Hill/Downtown Providence\n",
    ">> 2 \n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and\n",
    "    (pvd_nodes_tags.Value = \"library\") and \n",
    "    (((pvd_nodes.Lon >= -71.41) and (pvd_nodes.Lon <= -71.38) and \n",
    "    (pvd_nodes.Lat >= 41.825) and (pvd_nodes.Lat <= 41.857)) or \n",
    "    ((pvd_nodes.Lon >= -71.407) and (pvd_nodes.Lon <= -71.385) and \n",
    "    (pvd_nodes.Lat >= 41.818) and (pvd_nodes.Lat <= 41.825)));\n",
    "    \n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Value = \"library\") and \n",
    "    (pvd_nodes.Lon <= -71.36) and \n",
    "    (pvd_nodes.Lon >= -71.407) and \n",
    "    (pvd_nodes.Lat >= 41.813) and \n",
    "    (pvd_nodes.Lat <= 41.825);\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Trees\n",
    "Another important factor in deciding where to move is the amount of local green spaces. I'd like to feel as though I have some access to \"nature\" within walking distance of my apartment.\n",
    "\n",
    ">College Hill/East Providence\n",
    ">>206\n",
    "\n",
    ">Federal Hill/Downtown Providence\n",
    ">>256\n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Value = \"tree\") and \n",
    "    (((pvd_nodes.Lon >= -71.41) and (pvd_nodes.Lon <= -71.38) and \n",
    "    (pvd_nodes.Lat >= 41.825) and (pvd_nodes.Lat <= 41.857)) or \n",
    "    ((pvd_nodes.Lon >= -71.407) and (pvd_nodes.Lon <= -71.385) and \n",
    "    (pvd_nodes.Lat >= 41.818) and (pvd_nodes.Lat <= 41.825)));\n",
    "\n",
    "    sqlite3 >\n",
    "    SELECT pvd_nodes_tags.Value, count(*) as num \n",
    "    FROM pvd_nodes_tags, pvd_nodes \n",
    "    WHERE (pvd_nodes.ID = pvd_nodes_tags.ID) and \n",
    "    (pvd_nodes_tags.Value = \"tree\") and \n",
    "    (pvd_nodes.Lon <= -71.36) and \n",
    "    (pvd_nodes.Lon >= -71.407) and \n",
    "    (pvd_nodes.Lat >= 41.813) and \n",
    "    (pvd_nodes.Lat <= 41.825);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Recommendations for Improving the Data\n",
    "To facilitate a more accurate and user-informed exploration of the different neighborhoods around Providence, I would suggest adding \"neighborhood\" tags to the nodes and ways included in this data. This would great facilitate the ease at which one is able to search for different amenities by neighborhood within a larger metropolitan area.\n",
    "\n",
    "It would also be helpful to encourage contributors to include more data related to services available at different amenities. Notably, more data related to the location and hours of operations of dry cleaners would also be useful. It appears that the number of dry cleaners is underreported in the data. Given that the \"shop\" key may be underutilized as a means of identifying dry cleaning services, it may be helpful start including dry cleaner as a value within the more popular \"amenitiy\" key. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
